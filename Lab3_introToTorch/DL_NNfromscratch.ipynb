{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **There are two questions at the end of this notebook. Each one is for 5 marks. Question 3 is just for practice and not for the evaultion.**"
      ],
      "metadata": {
        "id": "WBd3KuTHSx3T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Jo34Bjd1HBU-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset"
      ],
      "metadata": {
        "id": "SOXl_45uHhqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "t_indep=pd.read_csv('/content/drive/My Drive/train.csv.csv')\n",
        "t_indep=t_indep.drop(t_indep.columns[[0]],axis=1)\n",
        "t_dep=pd.read_csv('/content/drive/My Drive/test.csv.csv')\n",
        "t_dep=t_dep.drop(t_dep.columns[[0]],axis=1)"
      ],
      "metadata": {
        "id": "YbIO8RGvHYpS",
        "outputId": "5d7a2904-5e76-411f-e090-9c9f4725a352",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t_indep)\n",
        "print(t_dep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZE8tKTsIRYx",
        "outputId": "58cf5be3-e303-4c1e-f2b5-2066e3040675"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Age  SibSp  Parch   LogFare  Sex_male  Sex_female  Pclass_1  Pclass_2  \\\n",
            "0    22.0      1      0  2.110213         1           0         0         0   \n",
            "1    38.0      1      0  4.280593         0           1         1         0   \n",
            "2    26.0      0      0  2.188856         0           1         0         0   \n",
            "3    35.0      1      0  3.990834         0           1         1         0   \n",
            "4    35.0      0      0  2.202765         1           0         0         0   \n",
            "..    ...    ...    ...       ...       ...         ...       ...       ...   \n",
            "886  27.0      0      0  2.639057         1           0         0         1   \n",
            "887  19.0      0      0  3.433987         0           1         1         0   \n",
            "888  24.0      1      2  3.196630         0           1         0         0   \n",
            "889  26.0      0      0  3.433987         1           0         1         0   \n",
            "890  32.0      0      0  2.169054         1           0         0         0   \n",
            "\n",
            "     Pclass_3  Embarked_C  Embarked_Q  Embarked_S  \n",
            "0           1           0           0           1  \n",
            "1           0           1           0           0  \n",
            "2           1           0           0           1  \n",
            "3           0           0           0           1  \n",
            "4           1           0           0           1  \n",
            "..        ...         ...         ...         ...  \n",
            "886         0           0           0           1  \n",
            "887         0           0           0           1  \n",
            "888         1           0           0           1  \n",
            "889         0           1           0           0  \n",
            "890         1           0           1           0  \n",
            "\n",
            "[891 rows x 12 columns]\n",
            "     Survived\n",
            "0           0\n",
            "1           1\n",
            "2           1\n",
            "3           1\n",
            "4           0\n",
            "..        ...\n",
            "886         0\n",
            "887         1\n",
            "888         0\n",
            "889         1\n",
            "890         0\n",
            "\n",
            "[891 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So PyTorch tensors allow us to use gradients and make life easier, so we'll convert these dataframe values into those\n"
      ],
      "metadata": {
        "id": "x-S4wJZeImKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_dep=torch.tensor(t_dep.values,dtype=torch.float)\n",
        "t_indep=torch.tensor(t_indep.values,dtype=torch.float)"
      ],
      "metadata": {
        "id": "ozAr0M2kIYt7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(t_indep.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhnmtoDSI-d-",
        "outputId": "4be6128f-0685-476a-dea9-ad9da537cb72"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([891, 12])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8WYCuXo7I_vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up a Linear Model"
      ],
      "metadata": {
        "id": "cF2Nj65QJK32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "n_coeff=t_indep.size()[1]\n",
        "coeffs=torch.rand(n_coeff)-0.5 #random values in range -0.5 to 0.5\n",
        "coeffs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcQ5EqW4JMRd",
        "outputId": "ccb805e3-594d-4dd8-82a7-0864bf141216"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3823,  0.4150, -0.1171,  0.4593, -0.1096,  0.1009, -0.2434,  0.2936,\n",
              "         0.4408, -0.3668,  0.4346,  0.0936])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizing values in each column\n",
        "\n",
        "This is done to prevent any one column dominating the prediction results, since a linear model is row*coeffs, very high initial values in some columns will lead to some columns dominating the final answer which we don't want"
      ],
      "metadata": {
        "id": "azttAfbBKfij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vals,indices = t_indep.max(dim =0)\n",
        "t_indep = t_indep / vals  #v cool line of code, think about why\n"
      ],
      "metadata": {
        "id": "WBkHocQOKHy9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds=(t_indep*coeffs).sum(axis=1)"
      ],
      "metadata": {
        "id": "jCDD7t2xMmCR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuaCiYBNMtzt",
        "outputId": "404e282f-39f9-46b6-cf72-364845024f0f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7371, 0.0391, 0.9206, 0.4639, 0.7542, 1.0459, 0.2906, 0.7982, 0.9089,\n",
              "        0.3994])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=torch.abs(preds-t_dep).mean()\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGe3svgVMv0A",
        "outputId": "bd0514d8-6aa3-45d9-ea37-9c61396a26e6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5584)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making functions for loss and predictions"
      ],
      "metadata": {
        "id": "Iqs_PBInNG0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred(coeffs,indeps):\n",
        "  return (indeps*coeffs).sum(axis=1)\n",
        "\n",
        "def calc_loss(coeffs,indeps,deps):\n",
        "  return torch.abs(pred(coeffs,indeps)-deps).mean()"
      ],
      "metadata": {
        "id": "HgxCzmLeM3iL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doing gradient descent"
      ],
      "metadata": {
        "id": "dgRgCGKpNYoC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coeffs.requires_grad_() #enables gradients for coeffs tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJnZUx6ONW-W",
        "outputId": "bb00c6bd-8bcb-4c33-bc19-38b597f46e32"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.3823,  0.4150, -0.1171,  0.4593, -0.1096,  0.1009, -0.2434,  0.2936,\n",
              "         0.4408, -0.3668,  0.4346,  0.0936], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=calc_loss(coeffs,t_indep,t_dep)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sshxzU--NlD8",
        "outputId": "2e9321ce-0324-48c5-9d22-1a0b87e0a65a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5584, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward() #calculates gradients"
      ],
      "metadata": {
        "id": "uFnT8Fo_NrDW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coeffs.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-UjpEz-NtkH",
        "outputId": "4e2cc4a3-e1a5-4b47-fbe5-0076235bef30"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0775,  0.0306,  0.0236,  0.1006,  0.1234,  0.1237, -0.0350,  0.0523,\n",
              "         0.2297, -0.0406,  0.0847,  0.2029])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each time you call loss.backwards, newly calculated gradients are accumulated (or added to current gradients)\n",
        "\n",
        "We use tensor.grad.zero_() to make the gradients zero after each step"
      ],
      "metadata": {
        "id": "9mWJEDwPN0Ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coeffs.grad.zero_()\n",
        "loss=calc_loss(coeffs,t_indep,t_dep)\n",
        "loss.backward()\n",
        "with torch.no_grad():\n",
        "  coeffs.sub_(coeffs.grad*0.1)\n",
        "  coeffs.grad.zero_()\n",
        "  print(calc_loss(coeffs,t_indep,t_dep))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1YWhxXnNxuk",
        "outputId": "d7d320cd-8190-4392-f0ef-9f3f3746803e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.5331)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making functions for this"
      ],
      "metadata": {
        "id": "9DZqLzt-Onr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_coeffs(coeffs,lr):\n",
        "  coeffs.sub_(coeffs.grad*lr)\n",
        "  coeffs.grad.zero_()"
      ],
      "metadata": {
        "id": "I4Y4tXa-Obh5"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_epoch(coeffs,lr):\n",
        "  loss=calc_loss(coeffs,t_indep,t_dep)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    update_coeffs(coeffs,lr)\n",
        "    print(f\"{loss:.3f}\", end=\"; \")\n"
      ],
      "metadata": {
        "id": "mfiaKkbKOuVR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_coeffs():\n",
        "  return (torch.rand(n_coeff)-0.5).requires_grad_()\n"
      ],
      "metadata": {
        "id": "6FNamSw9PAQ3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(epochs=3000, lr=0.01):\n",
        "    torch.manual_seed(442)\n",
        "    coeffs = init_coeffs()\n",
        "    for i in range(epochs): one_epoch(coeffs, lr=lr)\n",
        "    return coeffs"
      ],
      "metadata": {
        "id": "yzpj7KRxPMKF"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMFuZ7OMPRPy",
        "outputId": "fc98eb5c-7b68-4a69-e942-3d0f8b3d9e81"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.531; 0.531; 0.530; 0.529; 0.528; 0.528; 0.527; 0.526; 0.526; 0.525; 0.524; 0.523; 0.523; 0.522; 0.521; 0.521; 0.520; 0.519; 0.519; 0.518; 0.517; 0.517; 0.516; 0.515; 0.515; 0.514; 0.513; 0.513; 0.512; 0.511; 0.511; 0.510; 0.509; 0.509; 0.508; 0.508; 0.507; 0.506; 0.506; 0.505; 0.505; 0.504; 0.503; 0.503; 0.502; 0.502; 0.501; 0.500; 0.500; 0.499; 0.499; 0.498; 0.497; 0.497; 0.496; 0.496; 0.495; 0.494; 0.494; 0.493; 0.493; 0.492; 0.492; 0.491; 0.490; 0.490; 0.489; 0.489; 0.488; 0.487; 0.487; 0.486; 0.486; 0.485; 0.485; 0.484; 0.483; 0.483; 0.482; 0.482; 0.481; 0.481; 0.480; 0.479; 0.479; 0.478; 0.478; 0.477; 0.476; 0.476; 0.475; 0.475; 0.474; 0.474; 0.473; 0.472; 0.472; 0.471; 0.471; 0.470; 0.470; 0.469; 0.468; 0.468; 0.467; 0.467; 0.466; 0.466; 0.465; 0.464; 0.464; 0.463; 0.463; 0.462; 0.462; 0.461; 0.460; 0.460; 0.459; 0.459; 0.458; 0.458; 0.457; 0.456; 0.456; 0.455; 0.455; 0.454; 0.454; 0.453; 0.452; 0.452; 0.451; 0.451; 0.450; 0.450; 0.449; 0.449; 0.448; 0.448; 0.447; 0.446; 0.446; 0.445; 0.445; 0.444; 0.444; 0.443; 0.443; 0.442; 0.442; 0.441; 0.441; 0.440; 0.440; 0.440; 0.439; 0.439; 0.438; 0.438; 0.437; 0.437; 0.437; 0.436; 0.436; 0.436; 0.435; 0.435; 0.434; 0.434; 0.434; 0.433; 0.433; 0.433; 0.433; 0.432; 0.432; 0.432; 0.431; 0.431; 0.431; 0.431; 0.430; 0.430; 0.430; 0.430; 0.429; 0.429; 0.429; 0.429; 0.428; 0.428; 0.428; 0.428; 0.427; 0.427; 0.427; 0.427; 0.426; 0.426; 0.426; 0.426; 0.426; 0.425; 0.425; 0.425; 0.425; 0.425; 0.424; 0.424; 0.424; 0.424; 0.424; 0.423; 0.423; 0.423; 0.423; 0.423; 0.422; 0.422; 0.422; 0.422; 0.422; 0.421; 0.421; 0.421; 0.421; 0.421; 0.421; 0.421; 0.420; 0.420; 0.420; 0.420; 0.420; 0.420; 0.419; 0.419; 0.419; 0.419; 0.419; 0.419; 0.419; 0.418; 0.418; 0.418; 0.418; 0.418; 0.418; 0.418; 0.417; 0.417; 0.417; 0.417; 0.417; 0.417; 0.417; 0.417; 0.416; 0.416; 0.416; 0.416; 0.416; 0.416; 0.416; 0.416; 0.415; 0.415; 0.415; 0.415; 0.415; 0.415; 0.415; 0.415; 0.415; 0.414; 0.414; 0.414; 0.414; 0.414; 0.414; 0.414; 0.414; 0.414; 0.413; 0.413; 0.413; 0.413; 0.413; 0.413; 0.413; 0.413; 0.413; 0.413; 0.412; 0.412; 0.412; 0.412; 0.412; 0.412; 0.412; 0.412; 0.412; 0.412; 0.411; 0.411; 0.411; 0.411; 0.411; 0.411; 0.411; 0.411; 0.411; 0.411; 0.411; 0.410; 0.410; 0.410; 0.410; 0.410; 0.410; 0.410; 0.410; 0.410; 0.410; 0.410; 0.409; 0.409; 0.409; 0.409; 0.409; 0.409; 0.409; 0.409; 0.409; 0.409; 0.409; 0.409; 0.409; 0.408; 0.408; 0.408; 0.408; 0.408; 0.408; 0.408; 0.408; 0.408; 0.408; 0.408; 0.408; 0.408; 0.408; 0.408; 0.407; 0.407; 0.407; 0.407; 0.407; 0.407; 0.407; 0.407; 0.407; 0.407; 0.407; 0.407; 0.407; 0.407; 0.407; 0.407; 0.407; 0.407; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.406; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.405; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.404; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.403; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.402; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.401; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.400; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.399; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.398; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.397; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.396; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.395; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.394; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.393; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.392; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.391; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.390; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.389; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.388; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.387; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.384; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.384; 0.385; 0.387; 0.386; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.386; 0.385; 0.384; 0.384; 0.385; 0.384; 0.386; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.386; 0.386; 0.385; 0.385; 0.387; 0.386; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.387; 0.386; 0.385; 0.385; 0.386; 0.385; 0.384; 0.384; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.387; 0.386; 0.385; 0.385; 0.386; 0.385; 0.384; 0.385; 0.387; 0.386; 0.385; 0.385; 0.387; 0.386; 0.385; 0.384; 0.386; 0.385; 0.384; 0.384; 0.385; 0.387; 0.386; 0.385; 0.384; 0.385; 0.385; 0.386; 0.385; 0.385; 0.385; 0.387; 0.386; 0.385; 0.384; 0.386; 0.385; 0.384; 0.385; 0.386; 0.385; 0.385; 0.385; 0.387; 0.386; 0.385; 0.384; 0.384; 0.385; 0.387; 0.386; 0.385; 0.384; 0.385; 0.387; 0.386; 0.385; 0.384; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.387; 0.386; 0.385; 0.384; 0.385; 0.386; 0.385; 0.384; 0.385; 0.387; 0.386; 0.385; 0.384; 0.386; 0.385; 0.384; 0.385; 0.387; 0.386; 0.385; 0.384; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.387; 0.386; 0.385; 0.384; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.387; 0.386; 0.385; 0.384; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.387; 0.386; 0.385; 0.384; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.387; 0.386; 0.385; 0.384; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.387; 0.386; 0.385; 0.384; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.387; 0.386; 0.385; 0.384; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.387; 0.386; 0.385; 0.384; 0.385; 0.387; 0.386; 0.385; 0.384; 0.385; 0.387; 0.386; 0.385; 0.384; 0.385; 0.387; 0.386; 0.385; 0.384; 0.384; 0.385; 0.384; 0.384; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.384; 0.387; 0.386; 0.385; 0.384; 0.384; 0.386; 0.387; 0.386; 0.385; 0.384; 0.386; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.384; 0.387; 0.386; 0.385; 0.384; 0.386; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.384; 0.387; 0.386; 0.385; 0.384; 0.386; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.384; 0.387; 0.386; 0.385; 0.384; 0.386; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.384; 0.386; 0.385; 0.384; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.384; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.384; 0.386; 0.385; 0.384; 0.386; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.384; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.384; 0.385; 0.384; 0.385; 0.387; 0.386; 0.385; 0.384; 0.386; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.384; 0.386; 0.385; 0.384; 0.386; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.384; 0.387; 0.386; 0.385; 0.384; 0.385; 0.387; 0.386; 0.385; 0.384; 0.386; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.384; 0.385; 0.384; 0.386; 0.387; 0.386; 0.385; 0.384; 0.386; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.385; 0.384; 0.385; 0.388; 0.387; 0.386; 0.385; 0.384; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.384; 0.386; 0.385; 0.385; 0.387; 0.386; 0.385; 0.384; 0.386; 0.388; 0.387; 0.386; 0.385; 0.385; 0.388; 0.387; 0.386; 0.385; 0.384; 0.387; "
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0017,  0.0017,  0.0012, -0.0011, -0.3341, -0.3371,  0.3293,  0.3279,\n",
              "         0.3306,  0.0125,  0.0124,  0.0154], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(coeffs.grad) #shows us that the model has pretty much converged"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjvSfBnTYyZK",
        "outputId": "d89f53b0-e164-4eb7-fec6-4ee0b51900ca"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a full neural network"
      ],
      "metadata": {
        "id": "IFL0aRIeSmdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def preds(coeffs, indeps):\n",
        "    l1,l2,const = coeffs\n",
        "    res = F.relu(indeps@l1) # '@' is an optimized matrix product in python\n",
        "    res = res@l2 + const\n",
        "    return torch.sigmoid(res)\n",
        "\n"
      ],
      "metadata": {
        "id": "HzrXhsw0ZmJQ"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss(coeffs,indeps,deps):\n",
        "  return torch.abs(preds(coeffs,indeps)-deps).mean()"
      ],
      "metadata": {
        "id": "laEnaVCvZfV1"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_epoch(coeffs,lr):\n",
        "  loss=calc_loss(coeffs,t_indep,t_dep)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    update_coeffs(coeffs,lr)\n",
        "    print(f\"{loss:.3f}\", end=\"; \")"
      ],
      "metadata": {
        "id": "oGOB5iNSZX87"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(epochs=300, lr=0.1):\n",
        "    torch.manual_seed(442)\n",
        "    coeffs = init_coeffs()\n",
        "    for i in range(epochs): one_epoch(coeffs, lr=lr)\n",
        "    return coeffs"
      ],
      "metadata": {
        "id": "R5dXI41AVSQb"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_coeffs(n_hidden=60):\n",
        "    layer1 = (torch.rand(n_coeff, n_hidden)-0.5)/n_hidden\n",
        "    layer2 = torch.rand(n_hidden, 1)-0.3\n",
        "    const = torch.rand(1)[0]\n",
        "    return layer1.requires_grad_(),layer2.requires_grad_(),const.requires_grad_()"
      ],
      "metadata": {
        "id": "S12bjOPdPTOW"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gkti04UZUW-U"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_coeffs(coeffs, lr=0.1):\n",
        "    for layer in coeffs:\n",
        "        layer.sub_(layer.grad * lr)\n",
        "        layer.grad.zero_()"
      ],
      "metadata": {
        "id": "_cIXRlSiU28p"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coeffs=train_model()\n",
        "# update_coeffs(l1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmtMp_OMVAW5",
        "outputId": "78579194-3b64-4ef7-ba14-cad8caeecac3"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.524; 0.520; 0.518; 0.516; 0.514; 0.512; 0.510; 0.508; 0.506; 0.504; 0.501; 0.499; 0.497; 0.494; 0.492; 0.490; 0.487; 0.485; 0.483; 0.480; 0.478; 0.476; 0.473; 0.471; 0.468; 0.466; 0.463; 0.461; 0.459; 0.456; 0.454; 0.451; 0.449; 0.446; 0.444; 0.441; 0.439; 0.436; 0.434; 0.431; 0.429; 0.426; 0.424; 0.421; 0.418; 0.416; 0.413; 0.411; 0.408; 0.405; 0.403; 0.400; 0.397; 0.395; 0.392; 0.389; 0.386; 0.384; 0.381; 0.378; 0.375; 0.373; 0.370; 0.367; 0.364; 0.362; 0.359; 0.357; 0.354; 0.351; 0.349; 0.346; 0.344; 0.341; 0.339; 0.336; 0.334; 0.332; 0.329; 0.327; 0.325; 0.323; 0.321; 0.318; 0.316; 0.314; 0.312; 0.310; 0.309; 0.307; 0.305; 0.303; 0.301; 0.300; 0.298; 0.296; 0.295; 0.293; 0.292; 0.290; 0.289; 0.287; 0.286; 0.285; 0.283; 0.282; 0.281; 0.279; 0.278; 0.277; 0.276; 0.275; 0.274; 0.273; 0.272; 0.271; 0.270; 0.269; 0.268; 0.267; 0.266; 0.265; 0.264; 0.263; 0.263; 0.262; 0.261; 0.260; 0.259; 0.259; 0.258; 0.257; 0.257; 0.256; 0.255; 0.255; 0.254; 0.253; 0.253; 0.252; 0.252; 0.251; 0.251; 0.250; 0.250; 0.249; 0.249; 0.248; 0.248; 0.247; 0.247; 0.246; 0.246; 0.245; 0.245; 0.244; 0.244; 0.244; 0.243; 0.243; 0.242; 0.242; 0.242; 0.241; 0.241; 0.241; 0.240; 0.240; 0.240; 0.239; 0.239; 0.239; 0.238; 0.238; 0.238; 0.237; 0.237; 0.237; 0.236; 0.236; 0.236; 0.236; 0.235; 0.235; 0.235; 0.235; 0.234; 0.234; 0.234; 0.234; 0.233; 0.233; 0.233; 0.233; 0.232; 0.232; 0.232; 0.232; 0.232; 0.231; 0.231; 0.231; 0.231; 0.231; 0.230; 0.230; 0.230; 0.230; 0.230; 0.229; 0.229; 0.229; 0.229; 0.229; 0.229; 0.228; 0.228; 0.228; 0.228; 0.228; 0.228; 0.227; 0.227; 0.227; 0.227; 0.227; 0.227; 0.226; 0.226; 0.226; 0.226; 0.226; 0.226; 0.226; 0.225; 0.225; 0.225; 0.225; 0.225; 0.225; 0.225; 0.224; 0.224; 0.224; 0.224; 0.224; 0.224; 0.224; 0.224; 0.223; 0.223; 0.223; 0.223; 0.223; 0.223; 0.223; 0.223; 0.223; 0.222; 0.222; 0.222; 0.222; 0.222; 0.222; 0.222; 0.222; 0.222; 0.221; 0.221; 0.221; 0.221; 0.221; 0.221; 0.221; 0.221; 0.221; 0.221; 0.220; 0.220; 0.220; 0.220; 0.220; 0.220; 0.220; 0.220; 0.220; 0.220; 0.219; 0.219; 0.219; 0.219; 0.219; 0.219; 0.219; 0.219; 0.219; 0.219; 0.219; 0.218; 0.218; "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def acc(coeffs , t_indep , t_dep): return (t_dep.bool()==(preds(coeffs,t_indep)>0.5)).float().mean()"
      ],
      "metadata": {
        "id": "ldox7Va5VB-O"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc(coeffs , t_indep , t_dep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7YDLChmdtr_",
        "outputId": "4fa50643-1dcb-4256-b4b2-b9226f8cb510"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7868)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluative Component:\n",
        "1. Create a train/test split from the dataset\n",
        "\n",
        "2. Evaluate the testing split and it's accuracy\n",
        "\n",
        "optional: 3. Make the neural network 3 layer and evaluate accuracy"
      ],
      "metadata": {
        "id": "UYDON7ACeR7R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_data = pd.read_csv(\"/content/drive/My Drive/train.csv.csv\")\n",
        "full_res = pd.read_csv(\"/content/drive/My Drive/test.csv.csv\")\n",
        "full_data = full_data.drop(full_data.columns[[0]] , axis = 1)\n",
        "full_res = full_res.drop(full_res.columns[[0]] , axis = 1)"
      ],
      "metadata": {
        "id": "AmLWBpHMb_DS"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data = torch.tensor(full_data.values , dtype = float)\n",
        "full_res = torch.tensor(full_res.values , dtype = float)"
      ],
      "metadata": {
        "id": "Qx3Fy9A6iqxd"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a 80 by 20 split for train and test data respectively"
      ],
      "metadata": {
        "id": "4z3FdwWJdNwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ratio = int(0.8*len(full_data))\n",
        "train_set = full_data[:ratio]\n",
        "test_set = full_data[ratio:]\n",
        "\n",
        "train_set_res = full_res[:ratio]\n",
        "test_set_res = full_res[ratio:]"
      ],
      "metadata": {
        "id": "z0o9Er2ncytN"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy on test_set\n"
      ],
      "metadata": {
        "id": "z4Us5rkhdqP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc(coeffs , test_set.float() , test_set_res.float())"
      ],
      "metadata": {
        "id": "Z19cOaQod0Gd",
        "outputId": "f5509586-2877-4c3e-c47c-8c5379b6b7c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6536)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zv6yGkA0gKB9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}